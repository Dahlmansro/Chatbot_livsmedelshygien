{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "982e07ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CD\\anaconda3\\envs\\Chatbot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\CD\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "##  Installera bibliotek\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pdfplumber\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b915ffbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** ENKEL CHATBOT ***\n",
      "Skriv 'exit' för att avsluta\n",
      "Chatbot avslutad.\n"
     ]
    }
   ],
   "source": [
    "# Läs API-nyckeln\n",
    "with open(\".env\", \"r\") as f:\n",
    "    API_KEY = f.read().strip().split(\"=\")[1].strip()\n",
    "\n",
    "# Konfigurera API\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# Skapa modell\n",
    "model = genai.GenerativeModel(\"models/gemini-2.0-flash\")\n",
    "\n",
    "print(\"*** ENKEL CHATBOT ***\")\n",
    "print(\"Skriv 'exit' för att avsluta\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Vänta på input\n",
    "        message = input(\"\\n> \")\n",
    "        \n",
    "        # Avsluta om användaren skriver exit\n",
    "        if message.lower() == 'exit':\n",
    "            break\n",
    "            \n",
    "        # Skicka meddelande till AI\n",
    "        print(\"Väntar på svar...\")\n",
    "        response = model.generate_content(message)\n",
    "        \n",
    "        # Visa svaret\n",
    "        print(\"\\nAI:\", response.text)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ett fel inträffade: {e}\")\n",
    "\n",
    "print(\"Chatbot avslutad.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c453c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API_KEY är: AIzaS...\n"
     ]
    }
   ],
   "source": [
    "with open(\".env\", \"r\") as f:\n",
    "    API_KEY = f.read().strip().split(\"=\")[1].strip()\n",
    "\n",
    "print(f\"API_KEY är: {API_KEY[:5]}...\")  # Visa bara början"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c55900b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text sparad till: min_extraherade_text.txt\n",
      "Antal tabeller hittade: 10\n",
      "Första delen av extraherad text:\n",
      "\n",
      "--- SIDA 1 ---\n",
      "Visitas bransch- \n",
      "riktlinjer för  \n",
      "restauranger\n",
      "En beskrivning av hur livsmedelslagstiftningens krav på restaurang kan uppfyllas\n",
      "Denna riktlinje upprättades 2014 \n",
      "och uppdaterades  2021 04 16\n",
      "\n",
      "--- SIDA 2 ---\n",
      "\n",
      "--- SIDA 3 ---\n",
      "15\t\n",
      "Visitas branschriktlinjer för livsmedelshantering på restaurang\n",
      "17\t\n",
      "Dokumentation\n",
      "18\t\n",
      "Faroanalys\n",
      "12\t\n",
      "Utbildning och personalens kunskaper\n",
      "16\t\n",
      "Personlig hygien\n",
      "20\t\n",
      "Inköp\n",
      "24\t\n",
      "Mottagning av varor\n",
      "27\t\n",
      "Förvaring (torrt, kylt, fryst)\n",
      "32\t\n",
      "Matlagning\n",
      "39\t\n",
      "Varmhålln\n"
     ]
    }
   ],
   "source": [
    "import fitz  # pymupdf\n",
    "import pandas as pd\n",
    "\n",
    "def extract_and_save_text(pdf_path, output_text_file='extracted_text.txt'):\n",
    "    # Öppna PDF-dokumentet\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    all_text = \"\"\n",
    "    table_data = []\n",
    "    \n",
    "    # Gå igenom alla sidor\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        \n",
    "        # Extrahera text från sidan\n",
    "        page_text = page.get_text()\n",
    "        all_text += f\"\\n--- SIDA {page_num + 1} ---\\n\"\n",
    "        all_text += page_text\n",
    "        \n",
    "        # Extrahera tabeller\n",
    "        try:\n",
    "            tables = page.find_tables()\n",
    "            for i, table in enumerate(tables):\n",
    "                table_extract = table.extract()\n",
    "                df = pd.DataFrame(table_extract)\n",
    "                table_data.append(df)\n",
    "                \n",
    "                # Lägg till tabelldata i texten också\n",
    "                all_text += f\"\\n\\n--- TABELL {i+1} PÅ SIDA {page_num + 1} ---\\n\"\n",
    "                all_text += df.to_string(index=False)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Kunde inte extrahera tabeller från sida {page_num + 1}: {e}\")\n",
    "    \n",
    "    # Stäng dokumentet\n",
    "    doc.close()\n",
    "    \n",
    "    # Spara all text till fil\n",
    "    with open(output_text_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(all_text)\n",
    "    \n",
    "    print(f\"Text sparad till: {output_text_file}\")\n",
    "    print(f\"Antal tabeller hittade: {len(table_data)}\")\n",
    "    \n",
    "    return all_text, table_data\n",
    "\n",
    "# Användning\n",
    "pdf_path = \"Visita_Branschriktlinjer-print_2021.pdf\"\n",
    "text, tables = extract_and_save_text(pdf_path, 'min_extraherade_text.txt')\n",
    "\n",
    "# Visa första 500 tecken för att kontrollera\n",
    "print(\"Första delen av extraherad text:\")\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "53ca973b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal meningar: 2112\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "# Träna en ny tokenizer baserat på din PDF-text\n",
    "tokenizer = PunktSentenceTokenizer()\n",
    "tokenizer.train(text)\n",
    "\n",
    "# Dela upp texten i meningar\n",
    "sentences = tokenizer.tokenize(text)\n",
    "\n",
    "print(f\"Antal meningar: {len(sentences)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc910d2",
   "metadata": {},
   "source": [
    "Semantic Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9610a986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skapar chunks...\n",
      "✅ 862 chunks skapade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\CD\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 1. FÖRBÄTTRAD CHUNKING FUNKTION\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "def robust_pdf_chunking(text, target_size=500, overlap_sentences=1):\n",
    "    \"\"\"\n",
    "    Robust chunking som hanterar PDF-text utan tydliga styckebrytningar\n",
    "    \"\"\"\n",
    "    # Rensa och normalisera text\n",
    "    text = re.sub(r'\\r\\n', '\\n', text)\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Dela upp i meningar med NLTK\n",
    "    from nltk.tokenize import sent_tokenize\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    current_sentences = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        if not sentence:\n",
    "            continue\n",
    "            \n",
    "        # Testa om vi kan lägga till meningen\n",
    "        test_chunk = current_chunk + \" \" + sentence if current_chunk else sentence\n",
    "        \n",
    "        if len(test_chunk) <= target_size:\n",
    "            # Lägg till meningen\n",
    "            current_chunk = test_chunk\n",
    "            current_sentences.append(sentence)\n",
    "        else:\n",
    "            # Spara nuvarande chunk om den inte är tom\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "                \n",
    "                # Skapa överlappning\n",
    "                if overlap_sentences > 0 and len(current_sentences) > overlap_sentences:\n",
    "                    overlap_sents = current_sentences[-overlap_sentences:]\n",
    "                    current_chunk = \" \".join(overlap_sents) + \" \" + sentence\n",
    "                    current_sentences = overlap_sents + [sentence]\n",
    "                else:\n",
    "                    current_chunk = sentence\n",
    "                    current_sentences = [sentence]\n",
    "            else:\n",
    "                # Om första meningen är för lång, lägg till den ändå\n",
    "                current_chunk = sentence\n",
    "                current_sentences = [sentence]\n",
    "    \n",
    "    # Lägg till sista chunken\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# 2. SKAPA CHUNKS\n",
    "print(\"Skapar chunks...\")\n",
    "chunks = robust_pdf_chunking(text, target_size=500, overlap_sentences=1)\n",
    "\n",
    "print(f\"✅ {len(chunks)} chunks skapade\")\n",
    "\n",
    "# Spara chunks\n",
    "with open(\"semantic_chunks.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chunks, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656abe0f",
   "metadata": {},
   "source": [
    "Skapar embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7585ecd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skapar embeddings för 862 chunks...\n",
      "Bearbetar chunk 1/862\n",
      "Bearbetar chunk 2/862\n",
      "Bearbetar chunk 3/862\n",
      "Bearbetar chunk 4/862\n",
      "Bearbetar chunk 5/862\n",
      "Bearbetar chunk 6/862\n",
      "Bearbetar chunk 7/862\n",
      "Bearbetar chunk 8/862\n",
      "Bearbetar chunk 9/862\n",
      "Bearbetar chunk 10/862\n",
      "Bearbetar chunk 11/862\n",
      "Bearbetar chunk 12/862\n",
      "Bearbetar chunk 13/862\n",
      "Bearbetar chunk 14/862\n",
      "Bearbetar chunk 15/862\n",
      "Bearbetar chunk 16/862\n",
      "Bearbetar chunk 17/862\n",
      "Bearbetar chunk 18/862\n",
      "Bearbetar chunk 19/862\n",
      "Bearbetar chunk 20/862\n",
      "Bearbetar chunk 21/862\n",
      "Bearbetar chunk 22/862\n",
      "Bearbetar chunk 23/862\n",
      "Bearbetar chunk 24/862\n",
      "Bearbetar chunk 25/862\n",
      "Bearbetar chunk 26/862\n",
      "Bearbetar chunk 27/862\n",
      "Bearbetar chunk 28/862\n",
      "Bearbetar chunk 29/862\n",
      "Bearbetar chunk 30/862\n",
      "Bearbetar chunk 31/862\n",
      "Bearbetar chunk 32/862\n",
      "Bearbetar chunk 33/862\n",
      "Bearbetar chunk 34/862\n",
      "Bearbetar chunk 35/862\n",
      "Bearbetar chunk 36/862\n",
      "Bearbetar chunk 37/862\n",
      "Bearbetar chunk 38/862\n",
      "Bearbetar chunk 39/862\n",
      "Bearbetar chunk 40/862\n",
      "Bearbetar chunk 41/862\n",
      "Bearbetar chunk 42/862\n",
      "Bearbetar chunk 43/862\n",
      "Bearbetar chunk 44/862\n",
      "Bearbetar chunk 45/862\n",
      "Bearbetar chunk 46/862\n",
      "Bearbetar chunk 47/862\n",
      "Bearbetar chunk 48/862\n",
      "Bearbetar chunk 49/862\n",
      "Bearbetar chunk 50/862\n",
      "Bearbetar chunk 51/862\n",
      "Bearbetar chunk 52/862\n",
      "Bearbetar chunk 53/862\n",
      "Bearbetar chunk 54/862\n",
      "Bearbetar chunk 55/862\n",
      "Bearbetar chunk 56/862\n",
      "Bearbetar chunk 57/862\n",
      "Bearbetar chunk 58/862\n",
      "Bearbetar chunk 59/862\n",
      "Bearbetar chunk 60/862\n",
      "Bearbetar chunk 61/862\n",
      "Bearbetar chunk 62/862\n",
      "Bearbetar chunk 63/862\n",
      "Bearbetar chunk 64/862\n",
      "Bearbetar chunk 65/862\n",
      "Bearbetar chunk 66/862\n",
      "Bearbetar chunk 67/862\n",
      "Bearbetar chunk 68/862\n",
      "Bearbetar chunk 69/862\n",
      "Bearbetar chunk 70/862\n",
      "Bearbetar chunk 71/862\n",
      "Bearbetar chunk 72/862\n",
      "Bearbetar chunk 73/862\n",
      "Bearbetar chunk 74/862\n",
      "Bearbetar chunk 75/862\n",
      "Bearbetar chunk 76/862\n",
      "Bearbetar chunk 77/862\n",
      "Bearbetar chunk 78/862\n",
      "Bearbetar chunk 79/862\n",
      "Bearbetar chunk 80/862\n",
      "Bearbetar chunk 81/862\n",
      "Bearbetar chunk 82/862\n",
      "Bearbetar chunk 83/862\n",
      "Bearbetar chunk 84/862\n",
      "Bearbetar chunk 85/862\n",
      "Bearbetar chunk 86/862\n",
      "Bearbetar chunk 87/862\n",
      "Bearbetar chunk 88/862\n",
      "Bearbetar chunk 89/862\n",
      "Bearbetar chunk 90/862\n",
      "Bearbetar chunk 91/862\n",
      "Bearbetar chunk 92/862\n",
      "Bearbetar chunk 93/862\n",
      "Bearbetar chunk 94/862\n",
      "Bearbetar chunk 95/862\n",
      "Bearbetar chunk 96/862\n",
      "Bearbetar chunk 97/862\n",
      "Bearbetar chunk 98/862\n",
      "Bearbetar chunk 99/862\n",
      "Bearbetar chunk 100/862\n",
      "Bearbetar chunk 101/862\n",
      "Bearbetar chunk 102/862\n",
      "Bearbetar chunk 103/862\n",
      "Bearbetar chunk 104/862\n",
      "Bearbetar chunk 105/862\n",
      "Bearbetar chunk 106/862\n",
      "Bearbetar chunk 107/862\n",
      "Bearbetar chunk 108/862\n",
      "Bearbetar chunk 109/862\n",
      "Bearbetar chunk 110/862\n",
      "Bearbetar chunk 111/862\n",
      "Bearbetar chunk 112/862\n",
      "Bearbetar chunk 113/862\n",
      "Bearbetar chunk 114/862\n",
      "Bearbetar chunk 115/862\n",
      "Bearbetar chunk 116/862\n",
      "Bearbetar chunk 117/862\n",
      "Bearbetar chunk 118/862\n",
      "Bearbetar chunk 119/862\n",
      "Bearbetar chunk 120/862\n",
      "Bearbetar chunk 121/862\n",
      "Bearbetar chunk 122/862\n",
      "Bearbetar chunk 123/862\n",
      "Bearbetar chunk 124/862\n",
      "Bearbetar chunk 125/862\n",
      "Bearbetar chunk 126/862\n",
      "Bearbetar chunk 127/862\n",
      "Bearbetar chunk 128/862\n",
      "Bearbetar chunk 129/862\n",
      "Bearbetar chunk 130/862\n",
      "Bearbetar chunk 131/862\n",
      "Bearbetar chunk 132/862\n",
      "Bearbetar chunk 133/862\n",
      "Bearbetar chunk 134/862\n",
      "Bearbetar chunk 135/862\n",
      "Bearbetar chunk 136/862\n",
      "Bearbetar chunk 137/862\n",
      "Bearbetar chunk 138/862\n",
      "Bearbetar chunk 139/862\n",
      "Bearbetar chunk 140/862\n",
      "Bearbetar chunk 141/862\n",
      "Bearbetar chunk 142/862\n",
      "Bearbetar chunk 143/862\n",
      "Bearbetar chunk 144/862\n",
      "Bearbetar chunk 145/862\n",
      "Bearbetar chunk 146/862\n",
      "Bearbetar chunk 147/862\n",
      "Bearbetar chunk 148/862\n",
      "Bearbetar chunk 149/862\n",
      "Bearbetar chunk 150/862\n",
      "Bearbetar chunk 151/862\n",
      "Bearbetar chunk 152/862\n",
      "Bearbetar chunk 153/862\n",
      "Bearbetar chunk 154/862\n",
      "Bearbetar chunk 155/862\n",
      "Bearbetar chunk 156/862\n",
      "Bearbetar chunk 157/862\n",
      "Bearbetar chunk 158/862\n",
      "Bearbetar chunk 159/862\n",
      "Bearbetar chunk 160/862\n",
      "Bearbetar chunk 161/862\n",
      "Bearbetar chunk 162/862\n",
      "Bearbetar chunk 163/862\n",
      "Bearbetar chunk 164/862\n",
      "Bearbetar chunk 165/862\n",
      "Bearbetar chunk 166/862\n",
      "Bearbetar chunk 167/862\n",
      "Bearbetar chunk 168/862\n",
      "Bearbetar chunk 169/862\n",
      "Bearbetar chunk 170/862\n",
      "Bearbetar chunk 171/862\n",
      "Bearbetar chunk 172/862\n",
      "Bearbetar chunk 173/862\n",
      "Bearbetar chunk 174/862\n",
      "Bearbetar chunk 175/862\n",
      "Bearbetar chunk 176/862\n",
      "Bearbetar chunk 177/862\n",
      "Bearbetar chunk 178/862\n",
      "Bearbetar chunk 179/862\n",
      "Bearbetar chunk 180/862\n",
      "Bearbetar chunk 181/862\n",
      "Bearbetar chunk 182/862\n",
      "Bearbetar chunk 183/862\n",
      "Bearbetar chunk 184/862\n",
      "Bearbetar chunk 185/862\n",
      "Bearbetar chunk 186/862\n",
      "Bearbetar chunk 187/862\n",
      "Bearbetar chunk 188/862\n",
      "Bearbetar chunk 189/862\n",
      "Bearbetar chunk 190/862\n",
      "Bearbetar chunk 191/862\n",
      "Bearbetar chunk 192/862\n",
      "Bearbetar chunk 193/862\n",
      "Bearbetar chunk 194/862\n",
      "Bearbetar chunk 195/862\n",
      "Bearbetar chunk 196/862\n",
      "Bearbetar chunk 197/862\n",
      "Bearbetar chunk 198/862\n",
      "Bearbetar chunk 199/862\n",
      "Bearbetar chunk 200/862\n",
      "Bearbetar chunk 201/862\n",
      "Bearbetar chunk 202/862\n",
      "Bearbetar chunk 203/862\n",
      "Bearbetar chunk 204/862\n",
      "Bearbetar chunk 205/862\n",
      "Bearbetar chunk 206/862\n",
      "Bearbetar chunk 207/862\n",
      "Bearbetar chunk 208/862\n",
      "Bearbetar chunk 209/862\n",
      "Bearbetar chunk 210/862\n",
      "Bearbetar chunk 211/862\n",
      "Bearbetar chunk 212/862\n",
      "Bearbetar chunk 213/862\n",
      "Bearbetar chunk 214/862\n",
      "Bearbetar chunk 215/862\n",
      "Bearbetar chunk 216/862\n",
      "Bearbetar chunk 217/862\n",
      "Bearbetar chunk 218/862\n",
      "Bearbetar chunk 219/862\n",
      "Bearbetar chunk 220/862\n",
      "Bearbetar chunk 221/862\n",
      "Bearbetar chunk 222/862\n",
      "Bearbetar chunk 223/862\n",
      "Bearbetar chunk 224/862\n",
      "Bearbetar chunk 225/862\n",
      "Bearbetar chunk 226/862\n",
      "Bearbetar chunk 227/862\n",
      "Bearbetar chunk 228/862\n",
      "Bearbetar chunk 229/862\n",
      "Bearbetar chunk 230/862\n",
      "Bearbetar chunk 231/862\n",
      "Bearbetar chunk 232/862\n",
      "Bearbetar chunk 233/862\n",
      "Bearbetar chunk 234/862\n",
      "Bearbetar chunk 235/862\n",
      "Bearbetar chunk 236/862\n",
      "Bearbetar chunk 237/862\n",
      "Bearbetar chunk 238/862\n",
      "Bearbetar chunk 239/862\n",
      "Bearbetar chunk 240/862\n",
      "Bearbetar chunk 241/862\n",
      "Bearbetar chunk 242/862\n",
      "Bearbetar chunk 243/862\n",
      "Bearbetar chunk 244/862\n",
      "Bearbetar chunk 245/862\n",
      "Bearbetar chunk 246/862\n",
      "Bearbetar chunk 247/862\n",
      "Bearbetar chunk 248/862\n",
      "Bearbetar chunk 249/862\n",
      "Bearbetar chunk 250/862\n",
      "Bearbetar chunk 251/862\n",
      "Bearbetar chunk 252/862\n",
      "Bearbetar chunk 253/862\n",
      "Bearbetar chunk 254/862\n",
      "Bearbetar chunk 255/862\n",
      "Bearbetar chunk 256/862\n",
      "Bearbetar chunk 257/862\n",
      "Bearbetar chunk 258/862\n",
      "Bearbetar chunk 259/862\n",
      "Bearbetar chunk 260/862\n",
      "Bearbetar chunk 261/862\n",
      "Bearbetar chunk 262/862\n",
      "Bearbetar chunk 263/862\n",
      "Bearbetar chunk 264/862\n",
      "Bearbetar chunk 265/862\n",
      "Bearbetar chunk 266/862\n",
      "Bearbetar chunk 267/862\n",
      "Bearbetar chunk 268/862\n",
      "Bearbetar chunk 269/862\n",
      "Bearbetar chunk 270/862\n",
      "Bearbetar chunk 271/862\n",
      "Bearbetar chunk 272/862\n",
      "Bearbetar chunk 273/862\n",
      "Bearbetar chunk 274/862\n",
      "Bearbetar chunk 275/862\n",
      "Bearbetar chunk 276/862\n",
      "Bearbetar chunk 277/862\n",
      "Bearbetar chunk 278/862\n",
      "Bearbetar chunk 279/862\n",
      "Bearbetar chunk 280/862\n",
      "Bearbetar chunk 281/862\n",
      "Bearbetar chunk 282/862\n",
      "Bearbetar chunk 283/862\n",
      "Bearbetar chunk 284/862\n",
      "Bearbetar chunk 285/862\n",
      "Bearbetar chunk 286/862\n",
      "Bearbetar chunk 287/862\n",
      "Bearbetar chunk 288/862\n",
      "Bearbetar chunk 289/862\n",
      "Bearbetar chunk 290/862\n",
      "Bearbetar chunk 291/862\n",
      "Bearbetar chunk 292/862\n",
      "Bearbetar chunk 293/862\n",
      "Bearbetar chunk 294/862\n",
      "Bearbetar chunk 295/862\n",
      "Bearbetar chunk 296/862\n",
      "Bearbetar chunk 297/862\n",
      "Bearbetar chunk 298/862\n",
      "Bearbetar chunk 299/862\n",
      "Bearbetar chunk 300/862\n",
      "Bearbetar chunk 301/862\n",
      "Bearbetar chunk 302/862\n",
      "Bearbetar chunk 303/862\n",
      "Bearbetar chunk 304/862\n",
      "Bearbetar chunk 305/862\n",
      "Bearbetar chunk 306/862\n",
      "Bearbetar chunk 307/862\n",
      "Bearbetar chunk 308/862\n",
      "Bearbetar chunk 309/862\n",
      "Bearbetar chunk 310/862\n",
      "Bearbetar chunk 311/862\n",
      "Bearbetar chunk 312/862\n",
      "Bearbetar chunk 313/862\n",
      "Bearbetar chunk 314/862\n",
      "Bearbetar chunk 315/862\n",
      "Bearbetar chunk 316/862\n",
      "Bearbetar chunk 317/862\n",
      "Bearbetar chunk 318/862\n",
      "Bearbetar chunk 319/862\n",
      "Bearbetar chunk 320/862\n",
      "Bearbetar chunk 321/862\n",
      "Bearbetar chunk 322/862\n",
      "Bearbetar chunk 323/862\n",
      "Bearbetar chunk 324/862\n",
      "Bearbetar chunk 325/862\n",
      "Bearbetar chunk 326/862\n",
      "Bearbetar chunk 327/862\n",
      "Bearbetar chunk 328/862\n",
      "Bearbetar chunk 329/862\n",
      "Bearbetar chunk 330/862\n",
      "Bearbetar chunk 331/862\n",
      "Bearbetar chunk 332/862\n",
      "Bearbetar chunk 333/862\n",
      "Bearbetar chunk 334/862\n",
      "Bearbetar chunk 335/862\n",
      "Bearbetar chunk 336/862\n",
      "Bearbetar chunk 337/862\n",
      "Bearbetar chunk 338/862\n",
      "Bearbetar chunk 339/862\n",
      "Bearbetar chunk 340/862\n",
      "Bearbetar chunk 341/862\n",
      "Bearbetar chunk 342/862\n",
      "Bearbetar chunk 343/862\n",
      "Bearbetar chunk 344/862\n",
      "Bearbetar chunk 345/862\n",
      "Bearbetar chunk 346/862\n",
      "Bearbetar chunk 347/862\n",
      "Bearbetar chunk 348/862\n",
      "Bearbetar chunk 349/862\n",
      "Bearbetar chunk 350/862\n",
      "Bearbetar chunk 351/862\n",
      "Bearbetar chunk 352/862\n",
      "Bearbetar chunk 353/862\n",
      "Bearbetar chunk 354/862\n",
      "Bearbetar chunk 355/862\n",
      "Bearbetar chunk 356/862\n",
      "Bearbetar chunk 357/862\n",
      "Bearbetar chunk 358/862\n",
      "Bearbetar chunk 359/862\n",
      "Bearbetar chunk 360/862\n",
      "Bearbetar chunk 361/862\n",
      "Bearbetar chunk 362/862\n",
      "Bearbetar chunk 363/862\n",
      "Bearbetar chunk 364/862\n",
      "Bearbetar chunk 365/862\n",
      "Bearbetar chunk 366/862\n",
      "Bearbetar chunk 367/862\n",
      "Bearbetar chunk 368/862\n",
      "Bearbetar chunk 369/862\n",
      "Bearbetar chunk 370/862\n",
      "Bearbetar chunk 371/862\n",
      "Bearbetar chunk 372/862\n",
      "Bearbetar chunk 373/862\n",
      "Bearbetar chunk 374/862\n",
      "Bearbetar chunk 375/862\n",
      "Bearbetar chunk 376/862\n",
      "Bearbetar chunk 377/862\n",
      "Bearbetar chunk 378/862\n",
      "Bearbetar chunk 379/862\n",
      "Bearbetar chunk 380/862\n",
      "Bearbetar chunk 381/862\n",
      "Bearbetar chunk 382/862\n",
      "Bearbetar chunk 383/862\n",
      "Bearbetar chunk 384/862\n",
      "Bearbetar chunk 385/862\n",
      "Bearbetar chunk 386/862\n",
      "Bearbetar chunk 387/862\n",
      "Bearbetar chunk 388/862\n",
      "Bearbetar chunk 389/862\n",
      "Bearbetar chunk 390/862\n",
      "Bearbetar chunk 391/862\n",
      "Bearbetar chunk 392/862\n",
      "Bearbetar chunk 393/862\n",
      "Bearbetar chunk 394/862\n",
      "Bearbetar chunk 395/862\n",
      "Bearbetar chunk 396/862\n",
      "Bearbetar chunk 397/862\n",
      "Bearbetar chunk 398/862\n",
      "Bearbetar chunk 399/862\n",
      "Bearbetar chunk 400/862\n",
      "Bearbetar chunk 401/862\n",
      "Bearbetar chunk 402/862\n",
      "Bearbetar chunk 403/862\n",
      "Bearbetar chunk 404/862\n",
      "Bearbetar chunk 405/862\n",
      "Bearbetar chunk 406/862\n",
      "Bearbetar chunk 407/862\n",
      "Bearbetar chunk 408/862\n",
      "Bearbetar chunk 409/862\n",
      "Bearbetar chunk 410/862\n",
      "Bearbetar chunk 411/862\n",
      "Bearbetar chunk 412/862\n",
      "Bearbetar chunk 413/862\n",
      "Bearbetar chunk 414/862\n",
      "Bearbetar chunk 415/862\n",
      "Bearbetar chunk 416/862\n",
      "Bearbetar chunk 417/862\n",
      "Bearbetar chunk 418/862\n",
      "Bearbetar chunk 419/862\n",
      "Bearbetar chunk 420/862\n",
      "Bearbetar chunk 421/862\n",
      "Bearbetar chunk 422/862\n",
      "Bearbetar chunk 423/862\n",
      "Bearbetar chunk 424/862\n",
      "Bearbetar chunk 425/862\n",
      "Bearbetar chunk 426/862\n",
      "Bearbetar chunk 427/862\n",
      "Bearbetar chunk 428/862\n",
      "Bearbetar chunk 429/862\n",
      "Bearbetar chunk 430/862\n",
      "Bearbetar chunk 431/862\n",
      "Bearbetar chunk 432/862\n",
      "Bearbetar chunk 433/862\n",
      "Bearbetar chunk 434/862\n",
      "Bearbetar chunk 435/862\n",
      "Bearbetar chunk 436/862\n",
      "Bearbetar chunk 437/862\n",
      "Bearbetar chunk 438/862\n",
      "Bearbetar chunk 439/862\n",
      "Bearbetar chunk 440/862\n",
      "Bearbetar chunk 441/862\n",
      "Bearbetar chunk 442/862\n",
      "Bearbetar chunk 443/862\n",
      "Bearbetar chunk 444/862\n",
      "Bearbetar chunk 445/862\n",
      "Bearbetar chunk 446/862\n",
      "Bearbetar chunk 447/862\n",
      "Bearbetar chunk 448/862\n",
      "Bearbetar chunk 449/862\n",
      "Bearbetar chunk 450/862\n",
      "Bearbetar chunk 451/862\n",
      "Bearbetar chunk 452/862\n",
      "Bearbetar chunk 453/862\n",
      "Bearbetar chunk 454/862\n",
      "Bearbetar chunk 455/862\n",
      "Bearbetar chunk 456/862\n",
      "Bearbetar chunk 457/862\n",
      "Bearbetar chunk 458/862\n",
      "Bearbetar chunk 459/862\n",
      "Bearbetar chunk 460/862\n",
      "Bearbetar chunk 461/862\n",
      "Bearbetar chunk 462/862\n",
      "Bearbetar chunk 463/862\n",
      "Bearbetar chunk 464/862\n",
      "Bearbetar chunk 465/862\n",
      "Bearbetar chunk 466/862\n",
      "Bearbetar chunk 467/862\n",
      "Bearbetar chunk 468/862\n",
      "Bearbetar chunk 469/862\n",
      "Bearbetar chunk 470/862\n",
      "Bearbetar chunk 471/862\n",
      "Bearbetar chunk 472/862\n",
      "Bearbetar chunk 473/862\n",
      "Bearbetar chunk 474/862\n",
      "Bearbetar chunk 475/862\n",
      "Bearbetar chunk 476/862\n",
      "Bearbetar chunk 477/862\n",
      "Bearbetar chunk 478/862\n",
      "Bearbetar chunk 479/862\n",
      "Bearbetar chunk 480/862\n",
      "Bearbetar chunk 481/862\n",
      "Bearbetar chunk 482/862\n",
      "Bearbetar chunk 483/862\n",
      "Bearbetar chunk 484/862\n",
      "Bearbetar chunk 485/862\n",
      "Bearbetar chunk 486/862\n",
      "Bearbetar chunk 487/862\n",
      "Bearbetar chunk 488/862\n",
      "Bearbetar chunk 489/862\n",
      "Bearbetar chunk 490/862\n",
      "Bearbetar chunk 491/862\n",
      "Bearbetar chunk 492/862\n",
      "Bearbetar chunk 493/862\n",
      "Bearbetar chunk 494/862\n",
      "Bearbetar chunk 495/862\n",
      "Bearbetar chunk 496/862\n",
      "Bearbetar chunk 497/862\n",
      "Bearbetar chunk 498/862\n",
      "Bearbetar chunk 499/862\n",
      "Bearbetar chunk 500/862\n",
      "Bearbetar chunk 501/862\n",
      "Bearbetar chunk 502/862\n",
      "Bearbetar chunk 503/862\n",
      "Bearbetar chunk 504/862\n",
      "Bearbetar chunk 505/862\n",
      "Bearbetar chunk 506/862\n",
      "Bearbetar chunk 507/862\n",
      "Bearbetar chunk 508/862\n",
      "Bearbetar chunk 509/862\n",
      "Bearbetar chunk 510/862\n",
      "Bearbetar chunk 511/862\n",
      "Bearbetar chunk 512/862\n",
      "Bearbetar chunk 513/862\n",
      "Bearbetar chunk 514/862\n",
      "Bearbetar chunk 515/862\n",
      "Bearbetar chunk 516/862\n",
      "Bearbetar chunk 517/862\n",
      "Bearbetar chunk 518/862\n",
      "Bearbetar chunk 519/862\n",
      "Bearbetar chunk 520/862\n",
      "Bearbetar chunk 521/862\n",
      "Bearbetar chunk 522/862\n",
      "Bearbetar chunk 523/862\n",
      "Bearbetar chunk 524/862\n",
      "Bearbetar chunk 525/862\n",
      "Bearbetar chunk 526/862\n",
      "Bearbetar chunk 527/862\n",
      "Bearbetar chunk 528/862\n",
      "Bearbetar chunk 529/862\n",
      "Bearbetar chunk 530/862\n",
      "Bearbetar chunk 531/862\n",
      "Bearbetar chunk 532/862\n",
      "Bearbetar chunk 533/862\n",
      "Bearbetar chunk 534/862\n",
      "Bearbetar chunk 535/862\n",
      "Bearbetar chunk 536/862\n",
      "Bearbetar chunk 537/862\n",
      "Bearbetar chunk 538/862\n",
      "Bearbetar chunk 539/862\n",
      "Bearbetar chunk 540/862\n",
      "Bearbetar chunk 541/862\n",
      "Bearbetar chunk 542/862\n",
      "Bearbetar chunk 543/862\n",
      "Bearbetar chunk 544/862\n",
      "Bearbetar chunk 545/862\n",
      "Bearbetar chunk 546/862\n",
      "Bearbetar chunk 547/862\n",
      "Bearbetar chunk 548/862\n",
      "Bearbetar chunk 549/862\n",
      "Bearbetar chunk 550/862\n",
      "Bearbetar chunk 551/862\n",
      "Bearbetar chunk 552/862\n",
      "Bearbetar chunk 553/862\n",
      "Bearbetar chunk 554/862\n",
      "Bearbetar chunk 555/862\n",
      "Bearbetar chunk 556/862\n",
      "Bearbetar chunk 557/862\n",
      "Bearbetar chunk 558/862\n",
      "Bearbetar chunk 559/862\n",
      "Bearbetar chunk 560/862\n",
      "Bearbetar chunk 561/862\n",
      "Bearbetar chunk 562/862\n",
      "Bearbetar chunk 563/862\n",
      "Bearbetar chunk 564/862\n",
      "Bearbetar chunk 565/862\n",
      "Bearbetar chunk 566/862\n",
      "Bearbetar chunk 567/862\n",
      "Bearbetar chunk 568/862\n",
      "Bearbetar chunk 569/862\n",
      "Bearbetar chunk 570/862\n",
      "Bearbetar chunk 571/862\n",
      "Bearbetar chunk 572/862\n",
      "Bearbetar chunk 573/862\n",
      "Bearbetar chunk 574/862\n",
      "Bearbetar chunk 575/862\n",
      "Bearbetar chunk 576/862\n",
      "Bearbetar chunk 577/862\n",
      "Bearbetar chunk 578/862\n",
      "Bearbetar chunk 579/862\n",
      "Bearbetar chunk 580/862\n",
      "Bearbetar chunk 581/862\n",
      "Bearbetar chunk 582/862\n",
      "Bearbetar chunk 583/862\n",
      "Bearbetar chunk 584/862\n",
      "Bearbetar chunk 585/862\n",
      "Bearbetar chunk 586/862\n",
      "Bearbetar chunk 587/862\n",
      "Bearbetar chunk 588/862\n",
      "Bearbetar chunk 589/862\n",
      "Bearbetar chunk 590/862\n",
      "Bearbetar chunk 591/862\n",
      "Bearbetar chunk 592/862\n",
      "Bearbetar chunk 593/862\n",
      "Bearbetar chunk 594/862\n",
      "Bearbetar chunk 595/862\n",
      "Bearbetar chunk 596/862\n",
      "Bearbetar chunk 597/862\n",
      "Bearbetar chunk 598/862\n",
      "Bearbetar chunk 599/862\n",
      "Bearbetar chunk 600/862\n",
      "Bearbetar chunk 601/862\n",
      "Bearbetar chunk 602/862\n",
      "Bearbetar chunk 603/862\n",
      "Bearbetar chunk 604/862\n",
      "Bearbetar chunk 605/862\n",
      "Bearbetar chunk 606/862\n",
      "Bearbetar chunk 607/862\n",
      "Bearbetar chunk 608/862\n",
      "Bearbetar chunk 609/862\n",
      "Bearbetar chunk 610/862\n",
      "Bearbetar chunk 611/862\n",
      "Bearbetar chunk 612/862\n",
      "Bearbetar chunk 613/862\n",
      "Bearbetar chunk 614/862\n",
      "Bearbetar chunk 615/862\n",
      "Bearbetar chunk 616/862\n",
      "Bearbetar chunk 617/862\n",
      "Bearbetar chunk 618/862\n",
      "Bearbetar chunk 619/862\n",
      "Bearbetar chunk 620/862\n",
      "Bearbetar chunk 621/862\n",
      "Bearbetar chunk 622/862\n",
      "Bearbetar chunk 623/862\n",
      "Bearbetar chunk 624/862\n",
      "Bearbetar chunk 625/862\n",
      "Bearbetar chunk 626/862\n",
      "Bearbetar chunk 627/862\n",
      "Bearbetar chunk 628/862\n",
      "Bearbetar chunk 629/862\n",
      "Bearbetar chunk 630/862\n",
      "Bearbetar chunk 631/862\n",
      "Bearbetar chunk 632/862\n",
      "Bearbetar chunk 633/862\n",
      "Bearbetar chunk 634/862\n",
      "Bearbetar chunk 635/862\n",
      "Bearbetar chunk 636/862\n",
      "Bearbetar chunk 637/862\n",
      "Bearbetar chunk 638/862\n",
      "Bearbetar chunk 639/862\n",
      "Bearbetar chunk 640/862\n",
      "Bearbetar chunk 641/862\n",
      "Bearbetar chunk 642/862\n",
      "Bearbetar chunk 643/862\n",
      "Bearbetar chunk 644/862\n",
      "Bearbetar chunk 645/862\n",
      "Bearbetar chunk 646/862\n",
      "Bearbetar chunk 647/862\n",
      "Bearbetar chunk 648/862\n",
      "Bearbetar chunk 649/862\n",
      "Bearbetar chunk 650/862\n",
      "Bearbetar chunk 651/862\n",
      "Bearbetar chunk 652/862\n",
      "Bearbetar chunk 653/862\n",
      "Bearbetar chunk 654/862\n",
      "Bearbetar chunk 655/862\n",
      "Bearbetar chunk 656/862\n",
      "Bearbetar chunk 657/862\n",
      "Bearbetar chunk 658/862\n",
      "Bearbetar chunk 659/862\n",
      "Bearbetar chunk 660/862\n",
      "Bearbetar chunk 661/862\n",
      "Bearbetar chunk 662/862\n",
      "Bearbetar chunk 663/862\n",
      "Bearbetar chunk 664/862\n",
      "Bearbetar chunk 665/862\n",
      "Bearbetar chunk 666/862\n",
      "Bearbetar chunk 667/862\n",
      "Bearbetar chunk 668/862\n",
      "Bearbetar chunk 669/862\n",
      "Bearbetar chunk 670/862\n",
      "Bearbetar chunk 671/862\n",
      "Bearbetar chunk 672/862\n",
      "Bearbetar chunk 673/862\n",
      "Bearbetar chunk 674/862\n",
      "Bearbetar chunk 675/862\n",
      "Bearbetar chunk 676/862\n",
      "Bearbetar chunk 677/862\n",
      "Bearbetar chunk 678/862\n",
      "Bearbetar chunk 679/862\n",
      "Bearbetar chunk 680/862\n",
      "Bearbetar chunk 681/862\n",
      "Bearbetar chunk 682/862\n",
      "Bearbetar chunk 683/862\n",
      "Bearbetar chunk 684/862\n",
      "Bearbetar chunk 685/862\n",
      "Bearbetar chunk 686/862\n",
      "Bearbetar chunk 687/862\n",
      "Bearbetar chunk 688/862\n",
      "Bearbetar chunk 689/862\n",
      "Bearbetar chunk 690/862\n",
      "Bearbetar chunk 691/862\n",
      "Bearbetar chunk 692/862\n",
      "Bearbetar chunk 693/862\n",
      "Bearbetar chunk 694/862\n",
      "Bearbetar chunk 695/862\n",
      "Bearbetar chunk 696/862\n",
      "Bearbetar chunk 697/862\n",
      "Bearbetar chunk 698/862\n",
      "Bearbetar chunk 699/862\n",
      "Bearbetar chunk 700/862\n",
      "Bearbetar chunk 701/862\n",
      "Bearbetar chunk 702/862\n",
      "Bearbetar chunk 703/862\n",
      "Bearbetar chunk 704/862\n",
      "Bearbetar chunk 705/862\n",
      "Bearbetar chunk 706/862\n",
      "Bearbetar chunk 707/862\n",
      "Bearbetar chunk 708/862\n",
      "Bearbetar chunk 709/862\n",
      "Bearbetar chunk 710/862\n",
      "Bearbetar chunk 711/862\n",
      "Bearbetar chunk 712/862\n",
      "Bearbetar chunk 713/862\n",
      "Bearbetar chunk 714/862\n",
      "Bearbetar chunk 715/862\n",
      "Bearbetar chunk 716/862\n",
      "Bearbetar chunk 717/862\n",
      "Bearbetar chunk 718/862\n",
      "Bearbetar chunk 719/862\n",
      "Bearbetar chunk 720/862\n",
      "Bearbetar chunk 721/862\n",
      "Bearbetar chunk 722/862\n",
      "Bearbetar chunk 723/862\n",
      "Bearbetar chunk 724/862\n",
      "Bearbetar chunk 725/862\n",
      "Bearbetar chunk 726/862\n",
      "Bearbetar chunk 727/862\n",
      "Bearbetar chunk 728/862\n",
      "Bearbetar chunk 729/862\n",
      "Bearbetar chunk 730/862\n",
      "Bearbetar chunk 731/862\n",
      "Bearbetar chunk 732/862\n",
      "Bearbetar chunk 733/862\n",
      "Bearbetar chunk 734/862\n",
      "Bearbetar chunk 735/862\n",
      "Bearbetar chunk 736/862\n",
      "Bearbetar chunk 737/862\n",
      "Bearbetar chunk 738/862\n",
      "Bearbetar chunk 739/862\n",
      "Bearbetar chunk 740/862\n",
      "Bearbetar chunk 741/862\n",
      "Bearbetar chunk 742/862\n",
      "Bearbetar chunk 743/862\n",
      "Bearbetar chunk 744/862\n",
      "Bearbetar chunk 745/862\n",
      "Bearbetar chunk 746/862\n",
      "Bearbetar chunk 747/862\n",
      "Bearbetar chunk 748/862\n",
      "Bearbetar chunk 749/862\n",
      "Bearbetar chunk 750/862\n",
      "Bearbetar chunk 751/862\n",
      "Bearbetar chunk 752/862\n",
      "Bearbetar chunk 753/862\n",
      "Bearbetar chunk 754/862\n",
      "Bearbetar chunk 755/862\n",
      "Bearbetar chunk 756/862\n",
      "Bearbetar chunk 757/862\n",
      "Bearbetar chunk 758/862\n",
      "Bearbetar chunk 759/862\n",
      "Bearbetar chunk 760/862\n",
      "Bearbetar chunk 761/862\n",
      "Bearbetar chunk 762/862\n",
      "Bearbetar chunk 763/862\n",
      "Bearbetar chunk 764/862\n",
      "Bearbetar chunk 765/862\n",
      "Bearbetar chunk 766/862\n",
      "Bearbetar chunk 767/862\n",
      "Bearbetar chunk 768/862\n",
      "Bearbetar chunk 769/862\n",
      "Bearbetar chunk 770/862\n",
      "Bearbetar chunk 771/862\n",
      "Bearbetar chunk 772/862\n",
      "Bearbetar chunk 773/862\n",
      "Bearbetar chunk 774/862\n",
      "Bearbetar chunk 775/862\n",
      "Bearbetar chunk 776/862\n",
      "Bearbetar chunk 777/862\n",
      "Bearbetar chunk 778/862\n",
      "Bearbetar chunk 779/862\n",
      "Bearbetar chunk 780/862\n",
      "Bearbetar chunk 781/862\n",
      "Bearbetar chunk 782/862\n",
      "Bearbetar chunk 783/862\n",
      "Bearbetar chunk 784/862\n",
      "Bearbetar chunk 785/862\n",
      "Bearbetar chunk 786/862\n",
      "Bearbetar chunk 787/862\n",
      "Bearbetar chunk 788/862\n",
      "Bearbetar chunk 789/862\n",
      "Bearbetar chunk 790/862\n",
      "Bearbetar chunk 791/862\n",
      "Bearbetar chunk 792/862\n",
      "Bearbetar chunk 793/862\n",
      "Bearbetar chunk 794/862\n",
      "Bearbetar chunk 795/862\n",
      "Bearbetar chunk 796/862\n",
      "Bearbetar chunk 797/862\n",
      "Bearbetar chunk 798/862\n",
      "Bearbetar chunk 799/862\n",
      "Bearbetar chunk 800/862\n",
      "Bearbetar chunk 801/862\n",
      "Bearbetar chunk 802/862\n",
      "Bearbetar chunk 803/862\n",
      "Bearbetar chunk 804/862\n",
      "Bearbetar chunk 805/862\n",
      "Bearbetar chunk 806/862\n",
      "Bearbetar chunk 807/862\n",
      "Bearbetar chunk 808/862\n",
      "Bearbetar chunk 809/862\n",
      "Bearbetar chunk 810/862\n",
      "Bearbetar chunk 811/862\n",
      "Bearbetar chunk 812/862\n",
      "Bearbetar chunk 813/862\n",
      "Bearbetar chunk 814/862\n",
      "Bearbetar chunk 815/862\n",
      "Bearbetar chunk 816/862\n",
      "Bearbetar chunk 817/862\n",
      "Bearbetar chunk 818/862\n",
      "Bearbetar chunk 819/862\n",
      "Bearbetar chunk 820/862\n",
      "Bearbetar chunk 821/862\n",
      "Bearbetar chunk 822/862\n",
      "Bearbetar chunk 823/862\n",
      "Bearbetar chunk 824/862\n",
      "Bearbetar chunk 825/862\n",
      "Bearbetar chunk 826/862\n",
      "Bearbetar chunk 827/862\n",
      "Bearbetar chunk 828/862\n",
      "Bearbetar chunk 829/862\n",
      "Bearbetar chunk 830/862\n",
      "Bearbetar chunk 831/862\n",
      "Bearbetar chunk 832/862\n",
      "Bearbetar chunk 833/862\n",
      "Bearbetar chunk 834/862\n",
      "Bearbetar chunk 835/862\n",
      "Bearbetar chunk 836/862\n",
      "Bearbetar chunk 837/862\n",
      "Bearbetar chunk 838/862\n",
      "Bearbetar chunk 839/862\n",
      "Bearbetar chunk 840/862\n",
      "Bearbetar chunk 841/862\n",
      "Bearbetar chunk 842/862\n",
      "Bearbetar chunk 843/862\n",
      "Bearbetar chunk 844/862\n",
      "Bearbetar chunk 845/862\n",
      "Bearbetar chunk 846/862\n",
      "Bearbetar chunk 847/862\n",
      "Bearbetar chunk 848/862\n",
      "Bearbetar chunk 849/862\n",
      "Bearbetar chunk 850/862\n",
      "Bearbetar chunk 851/862\n",
      "Bearbetar chunk 852/862\n",
      "Bearbetar chunk 853/862\n",
      "Bearbetar chunk 854/862\n",
      "Bearbetar chunk 855/862\n",
      "Bearbetar chunk 856/862\n",
      "Bearbetar chunk 857/862\n",
      "Bearbetar chunk 858/862\n",
      "Bearbetar chunk 859/862\n",
      "Bearbetar chunk 860/862\n",
      "Bearbetar chunk 861/862\n",
      "Bearbetar chunk 862/862\n",
      "✅ 862 embeddings skapade\n"
     ]
    }
   ],
   "source": [
    "# SKAPA EMBEDDINGS FUNKTION\n",
    "def create_embeddings(text):\n",
    "    \"\"\"\n",
    "    Skapar embeddings med Gemini API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = genai.embed_content(\n",
    "            model=\"models/text-embedding-004\",\n",
    "            content=text,\n",
    "            task_type=\"retrieval_document\"\n",
    "        )\n",
    "        return {\"embedding\": result['embedding']}\n",
    "    except Exception as e:\n",
    "        print(f\"Fel vid skapande av embedding: {e}\")\n",
    "        return None\n",
    "    \n",
    "# SKAPA EMBEDDINGS FÖR ALLA CHUNKS\n",
    "print(f\"\\nSkapar embeddings för {len(chunks)} chunks...\")\n",
    "embeddings = []\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Bearbetar chunk {i+1}/{len(chunks)}\")\n",
    "    \n",
    "    embedding_result = create_embeddings(chunk)\n",
    "    if embedding_result:\n",
    "        embeddings.append(embedding_result[\"embedding\"])\n",
    "    else:\n",
    "        print(f\"Misslyckades med chunk {i+1}\")\n",
    "        \n",
    "    # Lägg till en liten paus för att undvika rate limiting\n",
    "    time.sleep(0.1)\n",
    "\n",
    "print(f\"✅ {len(embeddings)} embeddings skapade\")\n",
    "\n",
    "# Spara embeddings\n",
    "with open(\"embeddings_chunks.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea13f45",
   "metadata": {},
   "source": [
    "Semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7965a765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List, Any\n",
    "import numpy as np\n",
    "\n",
    "# Sätt upp grundläggande logging-konfiguration\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# UPPDATERAD COSINE SIMILARITY FUNKTION\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Beräknar cosine similarity mellan två vektorer\n",
    "    \"\"\"\n",
    "    # Konvertera till numpy arrays om det behövs\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    \n",
    "    # Beräkna cosine similarity\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0\n",
    "    \n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "def semantic_search(query: str, chunks: List[str], embeddings: List[List[float]], k: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Robust semantic search-funktion med felhantering, typkontroller och loggning.\n",
    "    \n",
    "    Parameters:\n",
    "    - query (str): Frågan som användaren söker efter\n",
    "    - chunks (List[str]): Lista med textdelar att söka i\n",
    "    - embeddings (List[List[float]]): Lista med embeddings för varje chunk\n",
    "    - k (int): Antal resultat att returnera\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: De k mest relevanta textdelarna\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not isinstance(query, str):\n",
    "            raise ValueError(\"Query måste vara en sträng.\")\n",
    "        if not isinstance(chunks, list) or not all(isinstance(c, str) for c in chunks):\n",
    "            raise ValueError(\"Chunks måste vara en lista med strängar.\")\n",
    "        if not isinstance(embeddings, list) or not all(isinstance(e, list) for e in embeddings):\n",
    "            raise ValueError(\"Embeddings måste vara en lista med listor (floats).\")\n",
    "        if len(chunks) != len(embeddings):\n",
    "            raise ValueError(\"Antalet chunks och embeddings måste vara lika.\")\n",
    "\n",
    "        # Skapa embedding för frågan\n",
    "        query_result = create_embeddings(query)\n",
    "        if not query_result or \"embedding\" not in query_result:\n",
    "            logging.warning(\"Kunde inte skapa embedding för frågan.\")\n",
    "            return chunks[:k]  # Fallback\n",
    "\n",
    "        query_embedding = query_result[\"embedding\"]\n",
    "\n",
    "        similarity_scores = []\n",
    "\n",
    "        # Beräkna cosine similarity mellan frågan och varje chunk\n",
    "        for i, chunk_embedding in enumerate(embeddings):\n",
    "            try:\n",
    "                similarity = cosine_similarity(query_embedding, chunk_embedding)\n",
    "                similarity_scores.append((i, similarity))\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Fel vid beräkning av similarity för chunk {i}: {e}\")\n",
    "                similarity_scores.append((i, 0))  # Sätt similarity till 0 vid fel\n",
    "\n",
    "        # Sortera efter högst likhet\n",
    "        similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Plocka ut de k bästa\n",
    "        top_indices = [index for index, _ in similarity_scores[:k]]\n",
    "\n",
    "        return [chunks[i] for i in top_indices]\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Fel i semantic_search: {e}\")\n",
    "        return chunks[:k]  # Fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2bf821",
   "metadata": {},
   "source": [
    "Respons Generering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "87c3b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(system_prompt, user_message):\n",
    "    \"\"\"\n",
    "    Genererar svar baserat på RAG\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Hitta relevanta chunks\n",
    "        relevant_chunks = semantic_search(user_message, chunks, embeddings)\n",
    "        \n",
    "        # Skapa kontext\n",
    "        context = \"\\n\\n\".join(relevant_chunks)\n",
    "        \n",
    "        # Skapa user prompt\n",
    "        user_prompt = f\"Frågan är: {user_message}\\n\\nHär är kontexten:\\n{context}\"\n",
    "        \n",
    "        # Kombinera system och user prompt\n",
    "        full_prompt = f\"{system_prompt}\\n\\n{user_prompt}\"\n",
    "        \n",
    "        # Generera svar\n",
    "        response = model.generate_content(full_prompt)\n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Fel vid generering av svar: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8304776e",
   "metadata": {},
   "source": [
    "Systempromt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78766e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Svara alltid med max 2 hela meningar. Avsluta alltid svaret med en punkt. Om du når tokengränsen, avsluta med en fullständig mening, även om det innebär att du måste korta svaret något. \n",
    "Använd enkel svenska utan listor eller markdown. Lägg till frågan: 'Vill du ha ett mer detaljerat svar?' sist.\n",
    "\n",
    "Exempel:\n",
    "Fråga: Vad är HACCP?\n",
    "Svar: HACCP är en metod för att identifiera faror i livsmedel. Den minskar risken för sjukdom. Vill du ha ett mer detaljerat svar?\n",
    "\n",
    "Fråga: {question}\n",
    "Svar:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d31eabe",
   "metadata": {},
   "source": [
    "Testar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30d3721c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TESTAR RAG-SYSTEMET\n",
      "==================================================\n",
      "\n",
      "Fråga: Vad är en faroanalys?\n",
      "\n",
      "Svar:\n",
      "En faroanalys identifierar och bedömer potentiella faror i livsmedelshanteringen. Den hjälper till att förebygga risker för konsumenterna. Vill du ha ett mer detaljerat svar?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TESTAR RAG-SYSTEMET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Testa med en fråga\n",
    "test_query = \"Vad är en faroanalys?\"\n",
    "print(f\"\\nFråga: {test_query}\")\n",
    "\n",
    "response = generate_response(system_prompt, test_query)\n",
    "if response:\n",
    "    print(\"\\nSvar:\")\n",
    "    print(response.text)\n",
    "else:\n",
    "    print(\"Kunde inte generera svar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8ad5abcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Avg Score: 0.979\n",
      "[2] Avg Score: 0.792\n",
      "[3] Avg Score: 0.835\n",
      "[4] Avg Score: 0.742\n",
      "[5] Avg Score: 0.754\n",
      "[6] Avg Score: 0.716\n",
      "\n",
      " Sammanställning av individuella poäng:\n",
      "                                                                               question  faithfulness  relevancy  similarity_score  avg_score\n",
      "                      Vad är HACCP och varför är det viktigt i en restaurangverksamhet?          1.00       1.00          0.937392     0.9791\n",
      "                                Vad menas med intern spårbarhet och är det ett lagkrav?          0.50       1.00          0.876225     0.7921\n",
      "                          Vilken information måste gäster kunna få om maten vid frågor?          0.60       1.00          0.904978     0.8350\n",
      "Vad ska göras om det uppstår problem med förpackningar eller temperaturer vid leverans?          0.70       0.70          0.826681     0.7422\n",
      "                                             Hur ska man dokumentera en genomförd kurs?          0.60       0.90          0.763055     0.7544\n",
      "                          I en faroanalys, vad ska man tänka på vad gäller upphettning?          0.50       0.90          0.747609     0.7159\n",
      "                                                                            GENOMSNITT:          0.65       0.92          0.840000     0.8031\n",
      "\n",
      "✅ Formaterad utvärdering sparad som JSON och CSV.\n"
     ]
    }
   ],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Funktion för cosine similarity med embeddings från genai\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = dot(vec1, vec2)\n",
    "    norm1 = norm(vec1)\n",
    "    norm2 = norm(vec2)\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "def calculate_cosine_similarity(text1, text2, model=\"models/embedding-001\"):\n",
    "    embedding1 = genai.embed_content(content=text1, model=model, task_type=\"semantic_similarity\")[\"embedding\"]\n",
    "    embedding2 = genai.embed_content(content=text2, model=model, task_type=\"semantic_similarity\")[\"embedding\"]\n",
    "    return cosine_similarity(embedding1, embedding2)\n",
    "\n",
    "# Faithfulness-prompt\n",
    "FAITHFULNESS_PROMPT = \"\"\"\n",
    "Bedöm hur faktamässigt korrekt AI:s svar är jämfört med det önskade svaret.\n",
    "Svara endast med ett tal mellan 0 och 1.\n",
    "\n",
    "Fråga: {question}\n",
    "Önskat svar: {true_answer}\n",
    "AI:s svar: {response}\n",
    "\n",
    "Poäng:\n",
    "\"\"\"\n",
    "\n",
    "# Relevancy-prompt\n",
    "RELEVANCY_PROMPT = \"\"\"\n",
    "Bedöm hur relevant AI:s svar är i förhållande till frågan.\n",
    "Svara endast med ett tal mellan 0 och 1.\n",
    "\n",
    "Fråga: {question}\n",
    "AI:s svar: {response}\n",
    "\n",
    "Poäng:\n",
    "\"\"\"\n",
    "\n",
    "# Läs in valideringsdata\n",
    "with open(\"validation_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    validation_data = json.load(f)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, item in enumerate(validation_data, 1):\n",
    "    question = item[\"question\"]\n",
    "    ideal_answer = item[\"ideal_answer\"]\n",
    "\n",
    "    try:\n",
    "        prompt = f\"{system_prompt}\\n\\nFråga: {question}\\nSvar:\"\n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config={\"max_output_tokens\": 100}\n",
    "        )\n",
    "        model_answer = response.text.strip()\n",
    "\n",
    "        result = {\n",
    "            \"question\": question,\n",
    "            \"ideal_answer\": ideal_answer,\n",
    "            \"model_answer\": model_answer\n",
    "        }\n",
    "\n",
    "        # Faithfulness\n",
    "        prompt_f = FAITHFULNESS_PROMPT.format(question=question, true_answer=ideal_answer, response=model_answer)\n",
    "        try:\n",
    "            resp_f = model.generate_content(prompt_f)\n",
    "            result[\"faithfulness\"] = max(0.0, min(1.0, float(resp_f.text.strip())))\n",
    "        except Exception as e:\n",
    "            print(f\"[{i}] Fel vid faithfulness: {e}\")\n",
    "            result[\"faithfulness\"] = 0.0\n",
    "\n",
    "        # Relevancy\n",
    "        prompt_r = RELEVANCY_PROMPT.format(question=question, response=model_answer)\n",
    "        try:\n",
    "            resp_r = model.generate_content(prompt_r)\n",
    "            result[\"relevancy\"] = max(0.0, min(1.0, float(resp_r.text.strip())))\n",
    "        except Exception as e:\n",
    "            print(f\"[{i}] Fel vid relevancy: {e}\")\n",
    "            result[\"relevancy\"] = 0.0\n",
    "\n",
    "        # Similarity\n",
    "        try:\n",
    "            result[\"similarity_score\"] = calculate_cosine_similarity(model_answer, ideal_answer)\n",
    "        except Exception as e:\n",
    "            print(f\"[{i}] Fel vid similarity: {e}\")\n",
    "            result[\"similarity_score\"] = 0.0\n",
    "\n",
    "        # Medelpoäng\n",
    "        result[\"avg_score\"] = round((result[\"faithfulness\"] + result[\"relevancy\"] + result[\"similarity_score\"]) / 3, 4)\n",
    "\n",
    "        print(f\"[{i}] Avg Score: {result['avg_score']:.3f}\")\n",
    "        results.append(result)\n",
    "\n",
    "    except Exception as main_e:\n",
    "        print(f\"[{i}] Fel vid fråga: {question}\\n{main_e}\")\n",
    "        continue\n",
    "\n",
    "# Skapa dataframe\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Skriv sammanställning till terminal\n",
    "print(\"\\n Sammanställning av individuella poäng:\")\n",
    "display_cols = [\"question\", \"faithfulness\", \"relevancy\", \"similarity_score\", \"avg_score\"]\n",
    "df_display = df[display_cols]\n",
    "overall_avg = round(df_display[\"avg_score\"].mean(), 4)\n",
    "\n",
    "summary_row = {\n",
    "    \"question\": \"GENOMSNITT:\",\n",
    "    \"faithfulness\": round(df_display[\"faithfulness\"].mean(), 2),\n",
    "    \"relevancy\": round(df_display[\"relevancy\"].mean(), 2),\n",
    "    \"similarity_score\": round(df_display[\"similarity_score\"].mean(), 2),\n",
    "    \"avg_score\": overall_avg\n",
    "}\n",
    "\n",
    "df_display = pd.concat([df_display, pd.DataFrame([summary_row])], ignore_index=True)\n",
    "print(df_display.to_string(index=False))\n",
    "\n",
    "# Skapa och spara formaterad utvärdering\n",
    "formatted_output = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    entry = f\"\"\"\n",
    "============================================================\n",
    "Fråga {i+1}:\n",
    "{row['question']}\n",
    "\n",
    "AI:s svar:\n",
    "{row['model_answer']}\n",
    "\n",
    "Poäng:\n",
    "- Faktatrohet (Faithfulness): {row['faithfulness']:.2f}\n",
    "- Relevans (Relevancy): {row['relevancy']:.2f}\n",
    "- Likhet med idealsvar (Similarity): {row['similarity_score']:.2f}\n",
    "- Medelpoäng: {row['avg_score']:.2f}\n",
    "\"\"\"\n",
    "    formatted_output.append(entry.strip())\n",
    "\n",
    "# Lägg till summerad poäng\n",
    "summary_entry = f\"\"\"\n",
    "============================================================\n",
    "SAMMANLAGD MEDELPOÄNG:\n",
    "\n",
    "- Genomsnittlig poäng över alla frågor: {overall_avg:.2f}\n",
    "\"\"\"\n",
    "formatted_output.append(summary_entry.strip())\n",
    "\n",
    "# Spara som JSON\n",
    "with open(\"komponent_utvardering.json\", \"w\", encoding=\"utf-8\") as f_json:\n",
    "    json.dump(formatted_output, f_json, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Spara som CSV\n",
    "df_formatted = pd.DataFrame({\"utvardering\": formatted_output})\n",
    "df_formatted.to_csv(\"komponent_utvardering.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"\\n✅ Formaterad utvärdering sparad som JSON och CSV.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a24d7f",
   "metadata": {},
   "source": [
    "## Utvärdering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "96adae7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Avg Score: 0.880\n",
      "[2] Avg Score: 0.785\n",
      "[3] Avg Score: 0.840\n",
      "[4] Avg Score: 0.819\n",
      "[5] Avg Score: 0.782\n",
      "[6] Avg Score: 0.718\n",
      "\n",
      " Sammanställning av individuella poäng:\n",
      "                                                                               question  faithfulness  relevancy  similarity_score  avg_score\n",
      "                      Vad är HACCP och varför är det viktigt i en restaurangverksamhet?          0.70       1.00          0.939741     0.8799\n",
      "                                Vad menas med intern spårbarhet och är det ett lagkrav?          0.50       1.00          0.854792     0.7849\n",
      "                          Vilken information måste gäster kunna få om maten vid frågor?          0.60       1.00          0.918353     0.8395\n",
      "Vad ska göras om det uppstår problem med förpackningar eller temperaturer vid leverans?          0.70       0.90          0.856158     0.8187\n",
      "                                             Hur ska man dokumentera en genomförd kurs?          0.70       0.80          0.844734     0.7816\n",
      "                          I en faroanalys, vad ska man tänka på vad gäller upphettning?          0.50       0.90          0.752510     0.7175\n",
      "                                                                            GENOMSNITT:          0.62       0.93          0.860000     0.8037\n",
      " Utvärdering klar\n"
     ]
    }
   ],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Funktion för cosine similarity med embeddings från genai\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = dot(vec1, vec2)\n",
    "    norm1 = norm(vec1)\n",
    "    norm2 = norm(vec2)\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "def calculate_cosine_similarity(text1, text2, model=\"models/embedding-001\"):\n",
    "    embedding1 = genai.embed_content(content=text1, model=model, task_type=\"semantic_similarity\")[\"embedding\"]\n",
    "    embedding2 = genai.embed_content(content=text2, model=model, task_type=\"semantic_similarity\")[\"embedding\"]\n",
    "    return cosine_similarity(embedding1, embedding2)\n",
    "\n",
    "# Faithfulness-prompt\n",
    "FAITHFULNESS_PROMPT = \"\"\"\n",
    "Bedöm hur faktamässigt korrekt AI:s svar är jämfört med det önskade svaret.\n",
    "Svara endast med ett tal mellan 0 och 1.\n",
    "\n",
    "Fråga: {question}\n",
    "Önskat svar: {true_answer}\n",
    "AI:s svar: {response}\n",
    "\n",
    "Poäng:\n",
    "\"\"\"\n",
    "\n",
    "# Relevancy-prompt\n",
    "RELEVANCY_PROMPT = \"\"\"\n",
    "Bedöm hur relevant AI:s svar är i förhållande till frågan.\n",
    "Svara endast med ett tal mellan 0 och 1.\n",
    "\n",
    "Fråga: {question}\n",
    "AI:s svar: {response}\n",
    "\n",
    "Poäng:\n",
    "\"\"\"\n",
    "\n",
    "# Läs in valideringsdata\n",
    "with open(\"validation_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    validation_data = json.load(f)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, item in enumerate(validation_data, 1):\n",
    "    question = item[\"question\"]\n",
    "    ideal_answer = item[\"ideal_answer\"]\n",
    "\n",
    "    try:\n",
    "         # 1. Generera AI-svar med systemprompt och tokenbegränsning\n",
    "        prompt = f\"{system_prompt}\\n\\nFråga: {question}\\nSvar:\"\n",
    "        response = model.generate_content(\n",
    "        prompt,\n",
    "        generation_config={\"max_output_tokens\": 100}\n",
    "        )\n",
    "        model_answer = response.text.strip()\n",
    "\n",
    "        result = {\n",
    "        \"question\": question,\n",
    "        \"ideal_answer\": ideal_answer,\n",
    "        \"model_answer\": model_answer\n",
    "        }\n",
    "\n",
    "\n",
    "        # 2. Faithfulness\n",
    "        prompt_f = FAITHFULNESS_PROMPT.format(question=question, true_answer=ideal_answer, response=model_answer)\n",
    "        try:\n",
    "            resp_f = model.generate_content(prompt_f)\n",
    "            result[\"faithfulness\"] = max(0.0, min(1.0, float(resp_f.text.strip())))\n",
    "        except Exception as e:\n",
    "            print(f\"[{i}] Fel vid faithfulness: {e}\")\n",
    "            result[\"faithfulness\"] = 0.0\n",
    "\n",
    "        # 3. Relevancy\n",
    "        prompt_r = RELEVANCY_PROMPT.format(question=question, response=model_answer)\n",
    "        try:\n",
    "            resp_r = model.generate_content(prompt_r)\n",
    "            result[\"relevancy\"] = max(0.0, min(1.0, float(resp_r.text.strip())))\n",
    "        except Exception as e:\n",
    "            print(f\"[{i}] Fel vid relevancy: {e}\")\n",
    "            result[\"relevancy\"] = 0.0\n",
    "\n",
    "        # 4. Similarity\n",
    "        try:\n",
    "            result[\"similarity_score\"] = calculate_cosine_similarity(model_answer, ideal_answer)\n",
    "        except Exception as e:\n",
    "            print(f\"[{i}] Fel vid similarity: {e}\")\n",
    "            result[\"similarity_score\"] = 0.0\n",
    "\n",
    "        # 5. Medelpoäng\n",
    "        result[\"avg_score\"] = round((\n",
    "            result[\"faithfulness\"] +\n",
    "            result[\"relevancy\"] +\n",
    "            result[\"similarity_score\"]\n",
    "        ) / 3, 4)\n",
    "\n",
    "        print(f\"[{i}] Avg Score: {result['avg_score']:.3f}\")\n",
    "        results.append(result)\n",
    "\n",
    "    except Exception as main_e:\n",
    "        print(f\"[{i}] Fel vid fråga: {question}\\n{main_e}\")\n",
    "        continue\n",
    "\n",
    "# Lägg till sammanlagd medelpoäng som sista rad i tabellen\n",
    "\n",
    "# Skapa dataframe för resultat\n",
    "print(\"\\n Sammanställning av individuella poäng:\")\n",
    "display_cols = [\"question\", \"faithfulness\", \"relevancy\", \"similarity_score\", \"avg_score\"]\n",
    "df_display = pd.DataFrame(results)[display_cols]\n",
    "\n",
    "overall_avg = round(df_display[\"avg_score\"].mean(), 4)\n",
    "summary_row = {\n",
    "    \"question\": \"GENOMSNITT:\",\n",
    "    \"faithfulness\": round(df_display[\"faithfulness\"].mean(), 2),\n",
    "    \"relevancy\": round(df_display[\"relevancy\"].mean(), 2),\n",
    "    \"similarity_score\": round(df_display[\"similarity_score\"].mean(), 2),\n",
    "    \"avg_score\": overall_avg\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Spara strukturerade resultatfiler direkt efter bearbetning\n",
    "with open(\"komponent_utvardering_rådata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "df.to_csv(\"komponent_utvardering_rådata.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "\n",
    "df_display = pd.concat([df_display, pd.DataFrame([summary_row])], ignore_index=True)\n",
    "print(df_display.to_string(index=False))\n",
    "print(\" Utvärdering klar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6ba92b",
   "metadata": {},
   "source": [
    "Omvandlar chatbot till Streamlit-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff4578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Läs in API-nyckel från .env\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# Skapa modell\n",
    "model = genai.GenerativeModel(\"models/gemini-2.0-flash\")\n",
    "\n",
    "st.title(\"🧠 Enkel Chatbot med Gemini\")\n",
    "st.write(\"Ställ en fråga i rutan nedan:\")\n",
    "\n",
    "# Användarens fråga\n",
    "user_input = st.text_input(\"Fråga\", \"\")\n",
    "\n",
    "if user_input:\n",
    "    try:\n",
    "        response = model.generate_content(user_input)\n",
    "        st.subheader(\"💬 Svar:\")\n",
    "        st.write(response.text)\n",
    "    except Exception as e:\n",
    "        st.error(f\"Något gick fel: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
